{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzCKsE+aOdqkoOPhfC3Taz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install xgboost\n","\n","import pandas as pd\n","\n","# Raw data GitHub link\n","url = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n","\n","# Load the dataset\n","df = pd.read_csv(url)\n","\n","# Preview the data\n","df.head()\n","\n","# Check shape\n","print(\"Dataset shape:\", df.shape)\n","\n","# Check for missing values\n","print(\"\\nMissing values per column:\")\n","print(df.isnull().sum())\n","\n","# See data types and basic info\n","df.info()\n","\n","# How many customers churned vs stayed\n","print(\"\\nChurn distribution:\")\n","print(df['Churn'].value_counts())\n","\n","# Remove spaces and convert to numeric\n","df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n","\n","# Check if there are now any missing values\n","print(\"Missing values in TotalCharges:\", df['TotalCharges'].isnull().sum())\n","\n","# Drop rows with missing TotalCharges\n","df.dropna(subset=['TotalCharges'], inplace=True)\n","\n","# Confirm new shape\n","print(\"New dataset shape:\", df.shape)\n","\n","# Drop customerID — it's just an identifier\n","df.drop('customerID', axis=1, inplace=True)\n","\n","# Convert target 'Churn' to binary: Yes → 1, No → 0\n","df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n","\n","# Use one-hot encoding for all categorical features\n","df_encoded = pd.get_dummies(df, drop_first=True)\n","\n","# Show shape after encoding\n","print(\"Shape after encoding:\", df_encoded.shape)\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Split features and target\n","X = df_encoded.drop('Churn', axis=1)\n","y = df_encoded['Churn']\n","\n","# Train-test split (stratified to preserve churn distribution)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","print(\"Training shape:\", X_train.shape)\n","print(\"Testing shape:\", X_test.shape)\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n","\n","# Initialize and train the model\n","model = LogisticRegression(max_iter=1000)\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test)\n","y_prob = model.predict_proba(X_test)[:, 1]\n","\n","# Evaluation\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test, y_pred))\n","print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n","\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Initialize and train model\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Predict\n","y_pred_rf = rf_model.predict(X_test)\n","y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n","\n","# Evaluate\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n","\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n","print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob_rf))\n","\n","import xgboost as xgb\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n","\n","# Create XGBoost classifier\n","xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n","\n","# Fit the model\n","xgb_model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred_xgb = xgb_model.predict(X_test)\n","y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n","\n","# Evaluate\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))\n","print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob_xgb))\n","\n","\n","readme_text = \"\"\"\n","# Customer Churn Prediction\n","\n","This project uses machine learning to predict whether a customer is likely to churn based on their account details and service usage. The goal is to help businesses retain customers by identifying churn risk early.\n","\n","---\n","\n","## Dataset\n","- Source: [IBM Telco Customer Churn Dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)\n","- Size: 7,032 rows × 21 columns\n","- Target: `Churn` (Yes/No)\n","\n","---\n","\n","##  Objective\n","To build and compare classification models that can predict customer churn with good accuracy, recall, and AUC score.\n","\n","---\n","\n","## Tools & Libraries\n","- Python\n","- pandas, numpy\n","- matplotlib, seaborn\n","- scikit-learn\n","- xgboost\n","\n","---\n","\n","## Models Tested\n","\n","| Model                | Accuracy | Recall (Churn) | F1 (Churn) | ROC-AUC |\n","|---------------------|----------|----------------|------------|---------|\n","| Logistic Regression | 80%      | **57%**        | **61%**    | **0.836** ✅ |\n","| Random Forest        | 79%      | 52%            | 57%        | 0.816   |\n","| XGBoost              | 77%      | 52%            | 54%        | 0.814   |\n","\n"," **Logistic Regression** performed best overall.\n","\n","---\n","\n","## Results Summary\n","- Churn rate: ~26%\n","- Most important features: `Contract`, `Tenure`, `MonthlyCharges`, `PaymentMethod`\n","- Final model achieves **balanced recall and precision**, with strong ROC-AUC\n","\n","---\n","\n","## Key Skills Demonstrated\n","- Data cleaning and feature engineering\n","- Classification modeling\n","- Handling imbalanced datasets\n","- Evaluation metrics (Confusion Matrix, ROC-AUC, F1)\n","- Business application of data science\n","\n","---\n","\n","## How to Run\n","\n","```bash\n","pip install -r requirements.txt\n","## Author\n","\n","Vanessa Chinhengo\n","\"\"\"\n","\n","# Save it as a file\n","with open(\"README.md\", \"w\") as f:\n","    f.write(readme_text)\n","\n","# Download it\n","from google.colab import files\n","files.download(\"README.md\")\n","\n","#create requirements.txt\n","requirements = \"\"\"\n","\n","\"\"\"\n","\n","#save it as a file\n","with open(\"requirements.txt\", \"w\") as f:\n","    f.write(\"pandas\\nnumpy\\nscikit-learn\\nmatplotlib\\nseaborn\\nxgboost\")\n","\n","# Download the file\n","from google.colab import files\n","files.download(\"requirements.txt\")"],"metadata":{"id":"5o0CNzZij9pS","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1751402872855,"user_tz":-120,"elapsed":9047,"user":{"displayName":"Vanessa Chinhengo","userId":"13172862159842254913"}},"outputId":"e3709f1f-d5e5-4ff7-a255-eab4b7b8dd9b"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n","Dataset shape: (7043, 21)\n","\n","Missing values per column:\n","customerID          0\n","gender              0\n","SeniorCitizen       0\n","Partner             0\n","Dependents          0\n","tenure              0\n","PhoneService        0\n","MultipleLines       0\n","InternetService     0\n","OnlineSecurity      0\n","OnlineBackup        0\n","DeviceProtection    0\n","TechSupport         0\n","StreamingTV         0\n","StreamingMovies     0\n","Contract            0\n","PaperlessBilling    0\n","PaymentMethod       0\n","MonthlyCharges      0\n","TotalCharges        0\n","Churn               0\n","dtype: int64\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7043 entries, 0 to 7042\n","Data columns (total 21 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   customerID        7043 non-null   object \n"," 1   gender            7043 non-null   object \n"," 2   SeniorCitizen     7043 non-null   int64  \n"," 3   Partner           7043 non-null   object \n"," 4   Dependents        7043 non-null   object \n"," 5   tenure            7043 non-null   int64  \n"," 6   PhoneService      7043 non-null   object \n"," 7   MultipleLines     7043 non-null   object \n"," 8   InternetService   7043 non-null   object \n"," 9   OnlineSecurity    7043 non-null   object \n"," 10  OnlineBackup      7043 non-null   object \n"," 11  DeviceProtection  7043 non-null   object \n"," 12  TechSupport       7043 non-null   object \n"," 13  StreamingTV       7043 non-null   object \n"," 14  StreamingMovies   7043 non-null   object \n"," 15  Contract          7043 non-null   object \n"," 16  PaperlessBilling  7043 non-null   object \n"," 17  PaymentMethod     7043 non-null   object \n"," 18  MonthlyCharges    7043 non-null   float64\n"," 19  TotalCharges      7043 non-null   object \n"," 20  Churn             7043 non-null   object \n","dtypes: float64(1), int64(2), object(18)\n","memory usage: 1.1+ MB\n","\n","Churn distribution:\n","Churn\n","No     5174\n","Yes    1869\n","Name: count, dtype: int64\n","Missing values in TotalCharges: 11\n","New dataset shape: (7032, 21)\n","Shape after encoding: (7032, 31)\n","Training shape: (5625, 30)\n","Testing shape: (1407, 30)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["[[916 117]\n"," [160 214]]\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.89      0.87      1033\n","           1       0.65      0.57      0.61       374\n","\n","    accuracy                           0.80      1407\n","   macro avg       0.75      0.73      0.74      1407\n","weighted avg       0.80      0.80      0.80      1407\n","\n","ROC-AUC Score: 0.8363897790040947\n","Confusion Matrix:\n"," [[917 116]\n"," [180 194]]\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.84      0.89      0.86      1033\n","           1       0.63      0.52      0.57       374\n","\n","    accuracy                           0.79      1407\n","   macro avg       0.73      0.70      0.71      1407\n","weighted avg       0.78      0.79      0.78      1407\n","\n","ROC-AUC Score: 0.8164903116927489\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:47:53] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n"," [[886 147]\n"," [181 193]]\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.83      0.86      0.84      1033\n","           1       0.57      0.52      0.54       374\n","\n","    accuracy                           0.77      1407\n","   macro avg       0.70      0.69      0.69      1407\n","weighted avg       0.76      0.77      0.76      1407\n","\n","ROC-AUC Score: 0.8141801823255044\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ea1d4896-2f0e-4694-94ce-7c8264745310\", \"README.md\", 1643)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_3cc3cbb6-42b1-4b51-b2f3-4dfb5cea248f\", \"requirements.txt\", 52)"]},"metadata":{}}]}]}